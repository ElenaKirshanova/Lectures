'''
	reference https://cims.nyu.edu/~regev/papers/gghattack.pdf
'''

d = 70
P = Primes()
q = 129


sk = Matrix(ZZ, d, d)

for i in range(d):
	sk[i,i] = q


print('generating random unimodular...')
random_U = random_matrix(ZZ, d, d, algorithm='unimodular')
random_U_inverse = random_U.inverse()
pk = random_U*sk

def simple_Babai(t):
	'''
	closest vector on the specific lattice generated by q*Id
	'''
	assert(len(t)==d)
	b = vector(ZZ, d)
	coeff = vector(ZZ, d)
	for i in range(len(t)):
		coeff[i] = round(t[i]/q)
		b[i] = coeff[i]*q

	#coeff_public = pk.solve_left(b) #same as below
	coeff_public = coeff*random_U_inverse
	return b, coeff_public

def sign(sk, mes):
	b, coeff = simple_Babai(mes)
	return coeff

def verify(pk, mes, sigma):
	b = sigma*pk
	for i in  range(len(mes)):
		assert(abs(mes[i]-b[i])<q/2)
	return (mes-b).norm().n()<(sqrt(d)*q/2).n()


def random_vector(d):
	'''
	messages are mapped to vectors
	'''
	t = vector(ZZ, d)
	for i in range(d):
		t[i] = ZZ.random_element(-1000*q, 1000*q)
	return t

def outer_product(w,v):
	return matrix([[a*b for b in w] for a in v])

N = 80000 #number of signatures
sigmas = [0]*N
bs = [0]*N
errs = [0]*N
print('generating ', N, 'signatures...')
for i in range(N):
	message = random_vector(d)
	sigmas[i]  = sign(sk, message)
	bs[i] = sigmas[i]*pk
	errs[i] = 2*(message - bs[i])
	ver = verify(pk, message, sigmas[i])
	assert(ver==True)

print('computing the average...')
R = RealField(800)
average = matrix(QQ, d, d)
for i in range(N):
	average+=outer_product(errs[i], errs[i])


for i in range(d):
	for j in range(d):
		#if i==j:
		#	average[i,j] = 3*(average[i,i]/N)
		#else:
			average[i,j] = 3*(average[i,j]/N)


#print('average[0]:', [average[0][i].n() for i in range(d)])
#print('average[1]:', [average[1][i].n() for i in range(d)])



print('computing the inverse of the average...')
average_inv = average.inverse()

print('computing cholesky decomposition...')
L = average_inv.cholesky()
#print(L[0])
LRR = matrix(R, d,d)
for i in range(d):
	for j in range(d):
		LRR[i,j] = R(L[i,j])

print('computing the inverse of cholesky')
LRR_inv = LRR.inverse()


print('computing C...')
C_ = matrix(RR, N, d)
N_good = 0
for i in range(N):
	tmp = errs[i]*LRR
	flag = True
	for j in range(d):
		if(abs(tmp[j])>1):
			flag=False
			break
	if flag:
		C_[N_good] = tmp
		N_good+=1

print('N_good:', N_good)

C = matrix(RR, N_good, d)
for i in range(N_good):
	C[i] = C_[i]
#	print(i, C[i])


C_test = sk*LRR
true_L = ((sk.transpose()*sk).inverse()).cholesky()
true_C = sk*true_L

#print('true_C:', (true_C*true_C.transpose())[0])
#print('C_test:', C_test[0])


def unit(d):
	uZZ = random_vector(d)
	normu = uZZ.norm()
	u = vector(RR, [uZZ[i]/normu for i in range(d)])
	return u

def exact_4moment(w):
	'''
		assumes V = Id
	'''
	assert(len(w)==d)
	res = 1./3 - 2./15*sum([w[i]^4 for i in range(d)])
	'''
	res = 0
	for i in range(d):
		for j in range(d):
			if i==j:
				res+=0.2*w[i]^4
			else:
				res+=(1./3)*w[i]^2*w[j]^2

	'''
	return res

def exact_4gradient(w):
	assert(len(w)==d)


	res = [0]*d
	for i in range(d):
		res[i] = 4./3*w[i] - 8./15*w[i]^3

	"""
	res2 = [0]*d
	for i in range(d):
		for j in range(d):
			res2[i]+=w[j]^2
		res2[i] = 4./3 * res2[i]*w[i] - 8./15*w[i]^3

	print(res2)
	print(res)
	assert(False)
	"""

	return res


def inner_prod(a,b):
	assert(len(a)==len(b))
	return sum([a[i]*b[i] for i in range(len(a))])


def decent():
	delta = 0.7
	w = unit(d)
	assert( abs(1 - w.norm() ) < 0.0001 )
	Niter = 0
	while Niter<5000:
		g =  vector(RR, d)
		for i in range(N_good):
			multiplier =  (inner_prod(w, C[i]))^3
			tmp = vector(RR, d)
			for j in range(d):
				tmp[j] = multiplier*C[i][j]
			g+=tmp

		for i in range(d):
			 g[i]/=N_good/4

		w_new = vector(RR,[w[i] - delta*g[i] for i in range(d)])
		norm_w_new = w_new.norm()
		for i in range(d):
			w_new[i]/=norm_w_new

		assert( abs(1 - w_new.norm() ) < 0.001 )

		mom_w = 0
		mom_w_new = 0
		for i in range(N_good):
			mom_w += (w.dot_product(C[i]))^4
			mom_w_new += (w_new.dot_product(C[i]))^4
		mom_w/=N_good
		mom_w_new/=N_good

		if mom_w_new > mom_w:
			return mom_w, w # the return does not mean we found the minimum, only that we went to a wrong direction
		else:
			w = w_new

		if abs(mom_w_new - 0.2)<0.005:
			return mom_w_new, w

		Niter+=1
		if Niter%100 == 0:
			print('in decent w:', w)
			#print('g approx:', g)
			#print('g exact: ', exact_4gradient(w) )
			print('mom_w:', mom_w, 'exact:', exact_4moment(w))
			#print('mom_w_new:', mom_w, 'exact:', exact_4moment(w_new))
	return mom_w, w

#mom_w, w =  decent()
#print('mom_w:', mom_w)
#print('w*LRR_inv:', w*LRR_inv)

Ndecents = 10
for i in range(Ndecents):
	mom_w, w =  decent()
	# check if there exists a row in C_test close to w
	if (abs(mom_w-0.2)<0.005):
		print('mom_w:', mom_w)
		print('w', w)
		print('w*LRR_inv:', w*LRR_inv)

	#if i%10 == 0:
	#	print('iterations passed in decents:', i)







"""
F = Integers(128)
Fx = PolynomialRing(F, 'x')

Fx2 = PolynomialRing(GF(2), 'x')
#K = CyclotomicField(256)

Fx_qou = Fx.quotient(x^N - 1, 'x')
Fx2_qou = Fx2.quotient(x^N - 1, 'x')

variable_x = Fx_qou.gen()

sparsity = ceil(73)

f_poly2 = Fx_qou(gen_small(sparsity, N))
f_poly = 1-2*Fx_qou(f_poly2)
g_poly = Fx_qou(gen_small(sparsity, N))

f_inverse = 1
# 128 = 2^7
for i in range(1, 7):
    f_inverse+=2^i * f_poly2^i

assert(f_poly*f_inverse==1)
h = Fx_qou(g_poly*f_inverse)

print('f:', f_poly, 'g:', g_poly, 'h:', h)




R = RealField(2000)
Rx.<x> = R[]

f_poly_R = Rx(list(f_poly))
g_poly_R = Rx(list(g_poly))
res_f = f_poly_R.resultant(x^N - 1)
res_g = g_poly_R.resultant(x^N - 1)
g, alpha, beta = xgcd(res_f, res_g)
assert(g==1)
print(g, alpha, beta)

roots = (x^N - 1).roots(ring=CDF)
Phi = Fx(list([1]*(N-1)))
Phi_quo = I

rho_f = 1
for i in range(len(roots)):
    rho_f*=f_poly_R(roots[i][0])
    print(roots[i][0], rho_f)
print(rho_f)
print(log(res_f).n())
"""
